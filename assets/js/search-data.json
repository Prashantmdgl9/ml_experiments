{
  
    
        "post0": {
            "title": "Imports and Downloads",
            "content": "from fastai.vision.all import * from fastbook import * matplotlib.rc(&#39;image&#39;, cmap=&#39;Greys&#39;) . Read the Data . # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here&#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only &quot;../input/&quot; directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): cnt = 0 for filename in filenames: cnt = cnt+1 #print(os.path.join(dirname, filename)) print(f&quot;Read {cnt} files from the directory- {dirname}&quot;) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#39;t be saved outside of the current session . train_dir = &quot;/kaggle/input/hindi-mnist/Hindi-MNIST/train&quot; train_path = Path(train_dir) valid_dir = &quot;/kaggle/input/hindi-mnist/Hindi-MNIST/test&quot; valid_path = Path(valid_dir) . zeroes = train_path.ls().sorted()[0].ls() ones = train_path.ls().sorted()[1].ls() twos = train_path.ls().sorted()[2].ls() threes = train_path.ls().sorted()[3].ls() fours = train_path.ls().sorted()[4].ls() fives = train_path.ls().sorted()[5].ls() sixes = train_path.ls().sorted()[6].ls() sevens = train_path.ls().sorted()[7].ls() eights = train_path.ls().sorted()[8].ls() nines = train_path.ls().sorted()[9].ls() . Print a digit to see what the data is . im = Image.open(sixes[0]) im . tensor(im)[4:10,4:10] . im.shape . The size of the images - 32 x 32 . im_t = tensor(im) df = pd.DataFrame(im_t[4:15,4:22]) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . Baseline Model . Distance from mean - Create a mean image for each of the digit from 0 to 9 . Dict = {0: zeroes,1:ones, 2: twos, 3: threes, 4: fours, 5: fives, 6: sixes, 7:sevens, 8:eights, 9:nines} . train_tensors = [] valid_tensors = [] for key in Dict: train_tensors.append([tensor(Image.open(o)) for o in Dict[key]]) valid_inf = valid_path.ls().sorted()[key].ls() valid_tensors.append([tensor(Image.open(o)) for o in valid_inf]) . len(train_tensors), len(valid_tensors), len(train_tensors[0]), len(valid_tensors[0]) . Stack the images for each of the digit class and find the mean digit(average of all the images for a digit) . stacked_train_tensors = [] for i in range(len(train_tensors)): stacked_train_tensors.append((torch.stack(train_tensors[i]).float()/255)) #print(i) print(len(stacked_train_tensors)), print(stacked_train_tensors[0].shape) . stacked_train_tensors_mean = [] for i in range(len(train_tensors)): stacked_train_tensors_mean.append((torch.stack(train_tensors[i]).float()/255).mean(0)) #print(i) print(len(stacked_train_tensors_mean)) . stacked_valid_tensors = [] for i in range(len(valid_tensors)): stacked_valid_tensors.append((torch.stack(valid_tensors[i]).float()/255)) #print(i) print(len(stacked_valid_tensors)), print(stacked_valid_tensors[0].shape) . stacked_train_tensors_mean[0].shape . show_image(stacked_train_tensors_mean[4]) . show_image(train_tensors[4][0]) . Testing errors . dist_4_abs = (train_tensors[2][0] - stacked_train_tensors_mean[4]).abs().mean() dist_4_sqr = ((train_tensors[2][0] - stacked_train_tensors_mean[4])**2).mean().sqrt() dist_4_abs, dist_4_sqr . dist_3_abs = (train_tensors[2][0] - stacked_train_tensors_mean[1]).abs().mean() dist_3_sqr = ((train_tensors[2][0] - stacked_train_tensors_mean[1])**2).mean().sqrt() dist_3_abs, dist_3_sqr . Let&#39;s define Error functions . def rms_error(a,b): return ((a-b)**2).mean((-1, -2)).sqrt() . for i in range(10): err = rms_error(train_tensors[4][0],stacked_train_tensors_mean[i]) print(err) . for i in range(10): print(F.l1_loss(train_tensors[4][0].float(),stacked_train_tensors_mean[i])) . for i in range(10): print(F.mse_loss(train_tensors[4][0].float(),stacked_train_tensors_mean[i])) . All the error functions have lowest error values for the distance between mean digits and sample image - train_tensors[4][0] which is a 4 . # All tensors in the validation set for a particular digit will be compared against the mean digit print(stacked_valid_tensors[4].shape), print(stacked_train_tensors_mean[4].shape) error = rms_error(stacked_valid_tensors[4], stacked_train_tensors_mean[4]) error.shape, error[0:15] . def predict_input(input_tensor): errors_in_pred = [] # errors = rms_error(input_tensor, stacked_train_tensors_mean[x]) for i in range(10): errors = rms_error(input_tensor, stacked_train_tensors_mean[i]) errors_in_pred.append(errors) #return torch.argmin(torch.stack(errors_in_pred), 0) # across the first axis, 0 specifies the axis return torch.argmin(torch.stack(errors_in_pred), 0) . y = predict_input(stacked_valid_tensors[9]) y, y.shape . (y == 9).float().mean() . accuracies = [] for i in range(10): #print(i) preds = predict_input(stacked_valid_tensors[i]) acc = (preds == i).float().mean() accuracies.append(acc) #print(preds) #pred_e = torch.argmin(err, 0) # print(preds) #accuracies.append((pred_e == i).float().mean()) accuracies . print(&#39;baseline model accuracy:&#39;, torch.stack(accuracies).mean()) . 82% baseline accuracy, let&#39;s try to beat that . Stochastic gradient descent . stacked_train_tensors[0][0].shape # one image from digit 0 . Entire data in row column format . lst = [stacked_train_tensors[i] for i in range(10)] # one row represents one image. image is flattened to 32*32 = 1024 pixels train_x = torch.cat(lst).view(-1, 32*32) train_x.shape . y_tensor = torch.tensor([]) for i in range(10): a = tensor(np.full(len(stacked_train_tensors[i]),i)) y_tensor = torch.cat([y_tensor, a]) y_tensor = y_tensor.unsqueeze(1) . y_tensor # PyTorch won&#39;t accept a FloatTensor as categorical target, so you&#39;ve to cast your tensor to LongTensor . y_tensor = y_tensor.type(torch.LongTensor) . y_tensor.shape . dset = list(zip(train_x,y_tensor)) . Same processing for valdiation set . valid_lst = [stacked_valid_tensors[i] for i in range(10)] # one row represents one image. image is flattened to 32*32 = 1024 pixels valid_x = torch.cat(valid_lst).view(-1, 32*32) valid_x.shape #train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) valid_y_tensor = torch.tensor([]) for i in range(10): a = tensor(np.full(len(stacked_valid_tensors[i]),i)) valid_y_tensor = torch.cat([valid_y_tensor, a]) valid_y_tensor = valid_y_tensor.unsqueeze(1) valid_dset = list(zip(valid_x,valid_y_tensor)) . valid_y_tensor.shape . Let&#39;s build the model . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() weights = init_params((32*32,1)) bias = init_params(1) . weights.shape, bias.shape . (train_x[0]*weights.T).sum() + bias . def linear1(xb): return xb@weights + bias preds = linear1(train_x) preds . train_x.shape . preds.shape . Dataloaders . dl_train = DataLoader(dset, batch_size=256, shuffle=True) dl_valid = DataLoader(valid_dset, batch_size=256) . dls = DataLoaders(dl_train, dl_valid) . len(dls.train) # 17000 train samples divided ub 256 batches 17000/256 ~ 67 . Loss function . def loss_func(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() . Testing . labels = [3,4,0] t = torch.tensor(labels) pred = torch.stack([ torch.tensor([-2, -3.5, -2.3, 3.5, -2.5, -2.1, -3.1, -3.4, -4, -3]), torch.tensor([-2, -3.5, -2.3, -2.5, 3.5, -2.1, -3.1, -3.4, -4, -3]), torch.tensor([3.5, -3.5, -2.3, -3.5, -2.5, -2.1, -3.1, -3.4, -4, -3]), ]) . pred.shape, t.shape, t, len(t) . loss_func(pred[1], t[0]) . sm = torch.softmax(pred, dim=1) idx = range(len(t)) sm, idx . sm[idx, t.T] . sm[0, ] . soft_m = torch.softmax(prediction, dim=1) index = tensor(range(len(y))) return soft_m[index.long(), y.long()].mean() . m = nn.Softmax(dim=1) . input = torch.randn(2, 3) input . m(input) . softmax_loss(pred, t) . loss_entropy(pred, t) . Testing ends here . def accuracy_metric(prediction, y): idx = torch.argmax(prediction, axis=1) # returns the index of the highest value return (idx==y.T).float().mean() . model = nn.Sequential( nn.Linear(32*32, 30), # 1024 input features and 30 output features nn.ReLU(), nn.Linear(30,10), ) . learn_loss_func = Learner(dls, model, loss_func=loss_func, opt_func=SGD, metrics=accuracy_metric) . learn_loss_func.fit(n_epoch=10, lr=0.1) . def softmax_loss(prediction, y): soft_m = torch.softmax(prediction, dim=1) index = tensor(range(len(y))) return soft_m[index.long(), y.long()].mean() . learn_softmax = Learner(dls, model, loss_func=softmax_loss, opt_func=SGD, metrics=accuracy_metric) . learn_softmax.fit(n_epoch=10, lr=0.1) . def loss_entropy(pred, y): #print(y.shape) y = y.long() if y.ndim &gt; 1: y = y.squeeze() # print(y.shape) return F.cross_entropy(pred, y) . learn_entropy = Learner(dls, model, loss_func=loss_entropy, opt_func=SGD, metrics=accuracy_metric) . learn_entropy.fit(n_epoch=30, lr=0.1) . plt.plot(L(learn_loss_func.recorder.values).itemgot(2), label=&#39;w/ simple_loss&#39;); plt.plot(L(learn_entropy.recorder.values).itemgot(2), label=&#39;w/ centropy&#39;); plt.plot(L(learn_softmax.recorder.values).itemgot(2), label=&#39;w/ softmax&#39;); plt.title(&#39;accuracy&#39;); plt.legend(loc=&#39;best&#39;); plt.xlabel(&#39;epoch&#39;); . y_tensor[10000:10010] . model(train_x)[10000:10010] . m = learn_entropy.model m . w, b = m[0].parameters() . for i in range(w.shape[0]): show_image(w[i].view(32,32)) .",
            "url": "https://prashantmdgl9.github.io/ml_experiments/2022/08/27/hindi-mnist-computer-vision-from-scratch-fastai.html",
            "relUrl": "/2022/08/27/hindi-mnist-computer-vision-from-scratch-fastai.html",
            "date": " • Aug 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://prashantmdgl9.github.io/ml_experiments/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://prashantmdgl9.github.io/ml_experiments/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://prashantmdgl9.github.io/ml_experiments/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://prashantmdgl9.github.io/ml_experiments/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
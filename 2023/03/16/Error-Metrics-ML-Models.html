<h1 id="error-metrics">Error Metrics</h1>

<h2 id="root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</h2>

<p>RMSE is the most popular evaluation metric used in regression problems. It follows an assumption that errors are unbiased and follow a normal distribution. Here are the key points to consider on RMSE:</p>

<ol>


<li>The power of ‘square root’ empowers this metric to show large number deviations.</li>
<li>The ‘squared’ nature of this metric helps to deliver more robust results, which prevent canceling the positive and negative error values. In other words, this metric aptly displays the plausible magnitude of the error term.</li>
<li>It avoids the use of absolute error values, which is highly undesirable in mathematical calculations.</li>
<li>When we have more samples, reconstructing the error distribution using RMSE is considered to be more reliable.</li>
<li>RMSE is highly affected by outlier values. Hence, make sure you’ve removed outliers from your data set prior to using this metric.</li>
<li>As compared to mean absolute error, RMSE gives higher weightage and punishes large errors.</li>


</ol>

<h2 id="r-squared">R Squared</h2>

<p>R is the correlation between the dep and indep vars.
R squared is just the square of R value.</p>

<p>It explains how much variation can the predictors explain about the dependent variable. It is dependent on the data and increases as you add more data.<br />
Also, it increases when you add more predictors even though the predictors don’t have any relationship to the dependent variable for example the price of the house and the gender of the person buying it shouldn’t be related but adding it to the model will improve the R squared value.
<br />
That’s why the concept of Adjusted R squared comes into pciture which penalises such predictors. The formula contains n and p which are number of data points and number of predictors and thus effects of high R squared can be mitigated.
<br />
R squared isn’t a notion for accuracy but how much variation in y can be explained by predictors.
<br />
R sq also tells how much less variation is around the fitted line compared to that of the mean line. A high value means there is less variation of the data around that line and it is a better line compared to the mean line.
<br /></p>

<h2 id="precision-and-recall">Precision and Recall</h2>

<p>Accuracy can be defined as correct identified items/ total items.
<br />
Apple and Orange classifier. If 7 correctly identified out of 10 then 70% accuracy but accuracy suffers from problem of imbalanced classes. 
If 990 oranges and 10 apples, then almost everything will be classified as an orange and we will still call the model to be 99% accurate.
<br /></p>

<p>Precision for apple,  Out of all that were classified as apple, total apples in the classifcation bucket/ total items classified as apples
3/5 = 60%
<br />
Recall for apple, correctly classified apples/ total apples in the system.
3/4 = 75%
<br /></p>

<p>Precision can be seen as a measure of quality, and recall as a measure of quantity. Higher precision means that an algorithm returns more relevant results than irrelevant ones, and high recall means that an algorithm returns most of the relevant results (whether or not irrelevant ones are also returned).Precision can be seen as a measure of quality, and recall as a measure of quantity. Higher precision means that an algorithm returns more relevant results than irrelevant ones, and high recall means that an algorithm returns most of the relevant results (whether or not irrelevant ones are also returned).</p>

<p><br /></p>

<p>Both precision and recall should be balanced. Not one at the cost of the other.
<br /></p>

<p>F1 score is Harmonic mean between precision and recall. It is a system that incorporates both precision and recall.</p>

